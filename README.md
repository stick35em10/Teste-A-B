# ğŸš€ ImplementaÃ§Ã£o de Teste A/B em ProduÃ§Ã£o
# ğŸ“‹ Arquitetura do Sistema

    teste-ab-production/
    â”‚
    â”œâ”€â”€ api/                          # ğŸ—ï¸ API para gerenciamento de testes
    â”‚   â”œâ”€â”€ app.py                   # FastAPI/FastAPI application
    â”‚   â”œâ”€â”€ endpoints/               # Endpoints da API
    â”‚   â”‚   â”œâ”€â”€ experiments.py       # Gerenciar experimentos
    â”‚   â”‚   â”œâ”€â”€ assignments.py       # AtribuiÃ§Ã£o de usuÃ¡rios
    â”‚   â”‚   â””â”€â”€ results.py           # Resultados e anÃ¡lises
    â”‚   â””â”€â”€ models/                  # Modelos de dados
    â”‚
    â”œâ”€â”€ core/                        # ğŸ§  LÃ³gica de negÃ³cio
    â”‚   â”œâ”€â”€ experiment_manager.py    # Gerenciador de experimentos
    â”‚   â”œâ”€â”€ assignment_engine.py     # Motor de atribuiÃ§Ã£o
    â”‚   â”œâ”€â”€ statistical_engine.py    # Motor estatÃ­stico
    â”‚   â””â”€â”€ data_processor.py        # Processamento de dados
    â”‚
    â”œâ”€â”€ database/                    # ğŸ—„ï¸ Camada de dados
    â”‚   â”œâ”€â”€ models.py               # Modelos SQLAlchemy
    â”‚   â”œâ”€â”€ crud.py                 # OperaÃ§Ãµes CRUD
    â”‚   â””â”€â”€ migrations/             # MigraÃ§Ãµes de banco
    â”‚
    â”œâ”€â”€ monitoring/                  # ğŸ“Š Monitoramento
    â”‚   â”œâ”€â”€ metrics.py              # Coleta de mÃ©tricas
    â”‚   â”œâ”€â”€ alerts.py               # Sistema de alertas
    â”‚   â””â”€â”€ dashboard.py            # Dashboard em tempo real
    â”‚
    â”œâ”€â”€ frontend/                    # ğŸ¨ Interface web (opcional)
    â”‚   â”œâ”€â”€ src/
    â”‚   â””â”€â”€ public/
    â”‚
    â”œâ”€â”€ tests/                       # ğŸ§ª Testes
    â”‚   â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ integration/
    â”‚   â””â”€â”€ e2e/
    â”‚
    â””â”€â”€ deployment/                  # ğŸ³ ConfiguraÃ§Ã£o de deploy
        â”œâ”€â”€ Dockerfile
        â”œâ”€â”€ docker-compose.yml
        â””â”€â”€ kubernetes/
#   ğŸ“Š Teste A/B: AnÃ¡lise de ConversÃ£o entre PÃ¡ginas Antiga e Nova

Este repositÃ³rio contÃ©m um notebook (teste_AB.ipynb) que realiza um teste A/B para comparar a taxa de conversÃ£o entre duas versÃµes de uma pÃ¡gina: a pÃ¡gina antiga (controle) e a pÃ¡gina nova (tratamento).

# ğŸ§ª Passo 1: Definir o Problema de NegÃ³cio
## ğŸ¯ Objetivo
Determinar se a nova pÃ¡gina (new_page) resulta em uma taxa de conversÃ£o maior do que a pÃ¡gina antiga (old_page).

## â“ HipÃ³teses
Hâ‚€ (HipÃ³tese Nula): A nova pÃ¡gina nÃ£o aumenta a taxa de conversÃ£o.

Hâ‚ (HipÃ³tese Alternativa): A nova pÃ¡gina aumenta a taxa de conversÃ£o.

# ğŸ§® Passo 2: Design do Experimento
ğŸ“ˆ ParÃ¢metros EstatÃ­sticos

NÃ­vel de confianÃ§a: 95% (confidence_level = 0.95)

NÃ­vel de significÃ¢ncia: 5% (significance_level = 0.05)

Poder estatÃ­stico: 80% (power = 0.80)

Efeito mÃ­nimo detectÃ¡vel (MDE): 2% (de 13% para 15%)

## ğŸ‘¥ Tamanho da Amostra
Foi calculado usando ** statsmodels.stats.power.NormalIndPower: **

python
effect_size = proportion_effectsize(0.13, 0.15)
sample_n = math.ceil(NormalIndPower().solve_power(effect_size, power=0.80, alpha=0.05))
## Resultado: 4.720 usuÃ¡rios por grupo.

# ğŸ—ƒï¸ Passo 3: Coleta e PreparaÃ§Ã£o dos Dados
## ğŸ“¦ Dados Originais
Total de linhas: 294.478

Colunas: user_id, timestamp, group, landing_page, converted

## ğŸ§¹ Limpeza dos Dados
RemoÃ§Ã£o de usuÃ¡rios duplicados (1,32% dos dados)

Dados finais: 286.690 linhas

## ğŸ² Amostragem
Grupo de controle: 4.720 usuÃ¡rios com old_page

Grupo de tratamento: 4.720 usuÃ¡rios com new_page

### Total da amostra: 9.440 usuÃ¡rios

# ğŸ“‰ Passo 4: Testando as HipÃ³teses
ğŸ“Š Taxas de ConversÃ£o

Grupo de controle (old_page): 11,55%

Grupo de tratamento (new_page): 12,90%

## ğŸ“ˆ Teste EstatÃ­stico
Foi utilizado um teste bicaudal para comparar as proporÃ§Ãµes, com:

Î± = 0,05

Poder = 0,80

# ğŸ’° Passo 5: ConclusÃµes e ConsideraÃ§Ãµes Financeiras
## âœ… Resultado
A nova pÃ¡gina apresentou uma taxa de conversÃ£o maior (12,90% vs 11,55%). 
A diferenÃ§a Ã© estatisticamente significativa ao nÃ­vel de 5%.

## ğŸ’¡ Impacto Financeiro
### Suponha que:

TrÃ¡fego mensal = 100.000 usuÃ¡rios

Valor mÃ©dio por conversÃ£o = R$ 50

Melhoria esperada:

ConversÃµes adicionais = (0,1290 - 0,1155) Ã— 100.000 â‰ˆ 1.350

### Ganho mensal = 1.350 Ã— R$ 50 = R$ 67.500

# ğŸš€ RecomendaÃ§Ã£o
Implementar a nova pÃ¡gina devido ao aumento significativo na taxa de conversÃ£o e retorno financeiro positivo.

# ğŸ› ï¸ Tecnologias Utilizadas
Python 3

Pandas

Statsmodels

Google Colab

# ğŸ‘¨â€ğŸ’» Como Executar
Clone o repositÃ³rio

Abra o notebook teste_AB.ipynb no Google Colab ou Jupyter

Execute as cÃ©lulas sequencialmente

# ğŸ“„ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT.

# ğŸ“Œ Contato
Se tiver dÃºvidas ou sugestÃµes, entre em contato!

Feito com â¤ï¸ e ğŸ“Š dados


# ğŸ§ª README - Teste A/B

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa de um teste A/B, desde a coleta de dados atÃ© a anÃ¡lise estatÃ­stica avanÃ§ada. O objetivo Ã© comparar duas versÃµes (A e B) de um produto, pÃ¡gina web ou feature para determinar qual performa melhor de acordo com mÃ©tricas prÃ©-definidas.

## ğŸ¯ Objetivos

- ğŸ“Š **Comparar a eficÃ¡cia** de duas variantes (A e B)
- ğŸ“ˆ **Determinar estatisticamente** qual versÃ£o performa melhor
- ğŸ¯ **Tomar decisÃµes baseadas em dados** para implementaÃ§Ã£o
- ğŸ” **Identificar insights** acionÃ¡veis para otimizaÃ§Ã£o

## ğŸ“‹ Estrutura do RepositÃ³rio

/teste_ab/
â”‚
â”œâ”€â”€ /data/ # ğŸ“ Dados brutos e processados
â”‚ â”œâ”€â”€ raw/ # ğŸ—ƒï¸ Dados originais
â”‚ â””â”€â”€ processed/ # âš™ï¸ Dados tratados
â”‚
â”œâ”€â”€ /notebooks/ # ğŸ““ Jupyter notebooks de anÃ¡lise
â”‚ â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚ â”œâ”€â”€ 02_ab_test_analysis.ipynb
â”‚ â””â”€â”€ 03_statistical_analysis.ipynb
â”‚
â”œâ”€â”€ /src/ # ğŸ’» CÃ³digo fonte
â”‚ â”œâ”€â”€ data_processing.py # ğŸ§¹ Scripts de limpeza
â”‚ â”œâ”€â”€ ab_test.py # ğŸ“Š AnÃ¡lise estatÃ­stica
â”‚ â””â”€â”€ visualization.py # ğŸ“ˆ GeraÃ§Ã£o de grÃ¡ficos
â”‚
â”œâ”€â”€ /results/ # ğŸ“Š Resultados e visualizaÃ§Ãµes
â”‚ â”œâ”€â”€ plots/ # ğŸ¨ GrÃ¡ficos e visualizaÃ§Ãµes
â”‚ â”œâ”€â”€ ab_test_report.pdf # ğŸ“„ RelatÃ³rio final
â”‚ â””â”€â”€ summary_results.csv # ğŸ’¾ Resultados sumarizados
â”‚
â”œâ”€â”€ requirements.txt # ğŸ“¦ DependÃªncias do projeto
â””â”€â”€ README.md # ğŸ“– Este arquivo


## ğŸ”§ PrÃ©-requisitos

- **Python 3.8+** ğŸ
- **Pip** (gerenciador de pacotes)
- **Bibliotecas listadas em requirements.txt**

### ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/teste-ab.git
cd teste-ab

# Instale as dependÃªncias
pip install -r requirements.txt




markdown
# ğŸ§ª README - Teste A/B

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa de um teste A/B, desde a coleta de dados atÃ© a anÃ¡lise estatÃ­stica avanÃ§ada. O objetivo Ã© comparar duas versÃµes (A e B) de um produto, pÃ¡gina web ou feature para determinar qual performa melhor de acordo com mÃ©tricas prÃ©-definidas.

## ğŸ¯ Objetivos

- ğŸ“Š **Comparar a eficÃ¡cia** de duas variantes (A e B)
- ğŸ“ˆ **Determinar estatisticamente** qual versÃ£o performa melhor
- ğŸ¯ **Tomar decisÃµes baseadas em dados** para implementaÃ§Ã£o
- ğŸ” **Identificar insights** acionÃ¡veis para otimizaÃ§Ã£o

## ğŸ“‹ Estrutura do RepositÃ³rio
/teste_ab/
â”‚
â”œâ”€â”€ /data/ # ğŸ“ Dados brutos e processados
â”‚ â”œâ”€â”€ raw/ # ğŸ—ƒï¸ Dados originais
â”‚ â””â”€â”€ processed/ # âš™ï¸ Dados tratados
â”‚
â”œâ”€â”€ /notebooks/ # ğŸ““ Jupyter notebooks de anÃ¡lise
â”‚ â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚ â”œâ”€â”€ 02_ab_test_analysis.ipynb
â”‚ â””â”€â”€ 03_statistical_analysis.ipynb
â”‚
â”œâ”€â”€ /src/ # ğŸ’» CÃ³digo fonte
â”‚ â”œâ”€â”€ data_processing.py # ğŸ§¹ Scripts de limpeza
â”‚ â”œâ”€â”€ ab_test.py # ğŸ“Š AnÃ¡lise estatÃ­stica
â”‚ â””â”€â”€ visualization.py # ğŸ“ˆ GeraÃ§Ã£o de grÃ¡ficos
â”‚
â”œâ”€â”€ /results/ # ğŸ“Š Resultados e visualizaÃ§Ãµes
â”‚ â”œâ”€â”€ plots/ # ğŸ¨ GrÃ¡ficos e visualizaÃ§Ãµes
â”‚ â”œâ”€â”€ ab_test_report.pdf # ğŸ“„ RelatÃ³rio final
â”‚ â””â”€â”€ summary_results.csv # ğŸ’¾ Resultados sumarizados
â”‚
â”œâ”€â”€ requirements.txt # ğŸ“¦ DependÃªncias do projeto
â””â”€â”€ README.md # ğŸ“– Este arquivo

text

## ğŸ”§ PrÃ©-requisitos

- **Python 3.8+** ğŸ
- **Pip** (gerenciador de pacotes)
- **Bibliotecas listadas em requirements.txt**

### ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/teste-ab.git
cd teste-ab

# Instale as dependÃªncias
pip install -r requirements.txt
ğŸš€ Como Executar
1. ğŸ“¥ PreparaÃ§Ã£o dos Dados
bash
python src/data_processing.py --input data/raw/ --output data/processed/
2. ğŸ“Š Executar AnÃ¡lise do Teste A/B
bash
python src/ab_test.py --data data/processed/ab_test_data.csv --metric conversion_rate
3. ğŸ“ˆ Gerar VisualizaÃ§Ãµes
bash
python src/visualization.py --data data/processed/ab_test_data.csv --output results/plots/
âš™ï¸ OpÃ§Ãµes de ParÃ¢metros
ParÃ¢metro	DescriÃ§Ã£o	PadrÃ£o	Exemplo
--data	Caminho para os dados	data/processed/	--data dados/experimento.csv
--metric	MÃ©trica a ser analisada	conversion_rate	--metric revenue_per_user
--confidence	NÃ­vel de confianÃ§a estatÃ­stica	0.95	--confidence 0.99
--alpha	NÃ­vel de significÃ¢ncia	0.05	--alpha 0.01
--output	DiretÃ³rio de saÃ­da	results/	--output resultados/
ğŸ“Š MÃ©tricas Analisadas
MÃ©trica	DescriÃ§Ã£o	Tipo de AnÃ¡lise
âœ… Taxa de conversÃ£o	Percentual de usuÃ¡rios que convertem	ProporÃ§Ã£o
â° Tempo na pÃ¡gina	Tempo mÃ©dio de permanÃªncia	ContÃ­nua
ğŸ–±ï¸ CTR	Click-Through Rate	ProporÃ§Ã£o
ğŸ’° Receita por usuÃ¡rio	Valor mÃ©dio gerado por usuÃ¡rio	ContÃ­nua
âŒ Taxa de rejeiÃ§Ã£o	Percentual de rejeiÃ§Ãµes	ProporÃ§Ã£o
ğŸ“‰ Taxa de retenÃ§Ã£o	Percentual de retenÃ§Ã£o de usuÃ¡rios	ProporÃ§Ã£o
ğŸ”„ Taxa de engajamento	NÃ­vel de engajamento dos usuÃ¡rios	ContÃ­nua
ğŸ“ˆ MÃ©todos EstatÃ­sticos Implementados
ğŸ¯ Testes de HipÃ³teses
Teste T para amostras independentes

Teste Z para proporÃ§Ãµes

Teste de Mann-Whitney U (nÃ£o paramÃ©trico)

ğŸ“Š AnÃ¡lise EstatÃ­stica
CÃ¡lculo do valor-p e significÃ¢ncia estatÃ­stica

Intervalos de confianÃ§a de 95% e 99%

Tamanho do efeito (Cohen's d, Glass's delta)

AnÃ¡lise de poder estatÃ­stico (Power Analysis)

Teste de normalidade (Shapiro-Wilk, Kolmogorov-Smirnov)

Teste de variÃ¢ncia (Levene's test, Bartlett's test)

ğŸ“¶ MÃ©todos AvanÃ§ados
AnÃ¡lise de regressÃ£o para controle de covariÃ¡veis

Testes de mÃºltiplas comparaÃ§Ãµes (correÃ§Ã£o de Bonferroni)

AnÃ¡lise de sensibilidade

ğŸ“ Exemplo de Uso Completo
python
from src.ab_test import ABTestAnalyzer
from src.visualization import ResultVisualizer
import pandas as pd

# ğŸ“¥ Carregar dados
data = pd.read_csv('data/processed/ab_test_data.csv')

# ğŸ”§ Inicializar analisador
analyzer = ABTestAnalyzer(
    data=data,
    group_column='variante',
    metric_column='conversion_rate',
    confidence_level=0.95
)

# ğŸ“Š Executar anÃ¡lise completa
results = analyzer.run_complete_analysis()

# ğŸ“ˆ Visualizar resultados
visualizer = ResultVisualizer(results)
visualizer.plot_conversion_rates(save_path='results/plots/conversion_rates.png')
visualizer.plot_confidence_intervals(save_path='results/plots/confidence_intervals.png')

# ğŸ“‹ Gerar relatÃ³rio HTML
report = analyzer.generate_html_report('results/ab_test_report.html')

print(f"ğŸ“Š Resultados da anÃ¡lise:")
print(f"Valor-p: {results['p_value']:.4f}")
print(f"Significativo: {results['is_significant']}")
print(f"Efeito: {results['effect_size']:.3f}")
ğŸ“Œ Resultados Esperados
ğŸ“„ RelatÃ³rio EstatÃ­stico
SumÃ¡rio executivo com recomendaÃ§Ãµes

Tabelas detalhadas com todas as mÃ©tricas

AnÃ¡lise de significÃ¢ncia estatÃ­stica e prÃ¡tica

Intervalos de confianÃ§a para todas as mÃ©tricas

ğŸ“Š VisualizaÃ§Ãµes
ğŸ“ˆ GrÃ¡ficos de barras comparativos

ğŸ“Š DistribuiÃ§Ãµes das mÃ©tricas por grupo

ğŸ¯ Intervalos de confianÃ§a visualizados

ğŸ“‰ TendÃªncias temporais (se aplicÃ¡vel)

ğŸ’¾ ExportaÃ§Ãµes
CSV/Excel com resultados detalhados

PDF/HTML com relatÃ³rio completo

JSON para integraÃ§Ã£o com outras ferramentas

ğŸ“… Cronograma do Projeto
Fase	DuraÃ§Ã£o	EntregÃ¡veis
â³ PreparaÃ§Ã£o	1 semana	DefiniÃ§Ã£o de mÃ©tricas, tamanho amostral
ğŸ“¥ Coleta	2-4 semanas	Dados brutos, logging implementado
ğŸ“Š AnÃ¡lise	1 semana	AnÃ¡lise estatÃ­stica, visualizaÃ§Ãµes
ğŸ“„ RelatÃ³rio	3 dias	RelatÃ³rio final, recomendaÃ§Ãµes
ğŸ¯ ImplementaÃ§Ã£o	1-2 semanas	Deployment da versÃ£o vencedora
ğŸ› ï¸ Ferramentas Utilizadas
ğŸ Linguagens e Frameworks
Python 3.8+ - Linguagem principal

Pandas - ManipulaÃ§Ã£o de dados

NumPy - ComputaÃ§Ã£o numÃ©rica

SciPy - EstatÃ­stica cientÃ­fica

StatsModels - Modelagem estatÃ­stica

ğŸ“Š VisualizaÃ§Ã£o
Matplotlib - GrÃ¡ficos estÃ¡ticos

Seaborn - VisualizaÃ§Ã£o estatÃ­stica

Plotly - GrÃ¡ficos interativos

ğŸ““ Ambiente de Desenvolvimento
Jupyter Notebook - AnÃ¡lise exploratÃ³ria

VS Code - IDE principal

Git - Controle de versÃ£o

ğŸ¤ Guia de ContribuiÃ§Ã£o
ğŸ´ Como Contribuir
Fork o projeto

Clone seu fork:

bash
git clone https://github.com/seu-usuario/teste-ab.git
Crie uma branch para sua feature:

bash
git checkout -b feature/nova-funcionalidade
Commit suas mudanÃ§as:

bash
git commit -m 'feat: adiciona nova mÃ©trica de engajamento'
Push para a branch:

bash
git push origin feature/nova-funcionalidade
Abra um Pull Request

ğŸ“ PadrÃµes de Commit
Tipo	Emoji	DescriÃ§Ã£o
feat	âœ¨	Nova funcionalidade
fix	ğŸ›	CorreÃ§Ã£o de bug
docs	ğŸ“š	DocumentaÃ§Ã£o
style	ğŸ’„	FormataÃ§Ã£o de cÃ³digo
refactor	â™»ï¸	RefatoraÃ§Ã£o de cÃ³digo
test	âœ…	AdiÃ§Ã£o de testes
chore	ğŸ”§	Tarefas de manutenÃ§Ã£o
ğŸ“š Recursos Adicionais
ğŸ“– DocumentaÃ§Ã£o
ğŸ“Š Guia Completo de Testes A/B

ğŸ§® Calculadora de Tamanho de Amostra

ğŸ“ˆ Artigos sobre EstatÃ­stica

ğŸ“ Cursos Recomendados
ğŸ“Š EstatÃ­stica para Data Science

ğŸ¯ Testes A/B na PrÃ¡tica

ğŸ“ˆ VisualizaÃ§Ã£o de Dados

ğŸ”§ Ferramentas Ãšteis
ğŸ“ Calculadora EstatÃ­stica Online

ğŸ“Š Gerador de GrÃ¡ficos

ğŸ¯ Simulador de Testes A/B

ğŸ› Troubleshooting
Problemas Comuns
Erro de dependÃªncias:

bash
pip install --upgrade -r requirements.txt
Dados corrompidos:

bash
python src/data_processing.py --check-integrity
MemÃ³ria insuficiente:

bash
python src/ab_test.py --chunk-size 1000
ğŸ“Š OtimizaÃ§Ã£o de Performance
Para conjuntos de dados grandes:

bash
# Usar processamento em chunks
python src/ab_test.py --chunk-size 5000 --use-dask

# Habilitar cache de resultados
python src/ab_test.py --enable-cache
ğŸ“§ Suporte e Contato
Para dÃºvidas, sugestÃµes ou problemas:

JosÃ© Dinis Carlos Cabicho
ğŸ“§ Email: jcabicho@gmail.com
ğŸ’¼ LinkedIn: linkedin.com/in/jose-cabicho
ğŸ™ GitHub: github.com/jcabicho
ğŸ¦ Twitter: @cabicho

ğŸš€ Relatar Problemas
Encontrou um bug? Por favor, abra uma issue no GitHub incluindo:

ğŸ“‹ DescriÃ§Ã£o detalhada do problema

ğŸ” Passos para reproduzir

ğŸ“Š Dados de exemplo (se aplicÃ¡vel)

ğŸ–¥ï¸ ConfiguraÃ§Ã£o do ambiente

ğŸ“„ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para detalhes.

ğŸ™Œ Agradecimentos
Equipe da Escola de Dados pelo desafio

Comunidade Python pelas bibliotecas incrÃ­veis

Stack Overflow pelas soluÃ§Ãµes compartilhadas

â­ Este projeto demonstra competÃªncias avanÃ§adas em teste A/B, anÃ¡lise estatÃ­stica e tomada de decisÃ£o baseada em dados.

ğŸš€ Pronto para transformar dados em decisÃµes!


# ğŸ§ª README - Teste A/B

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa de um teste A/B, desde a coleta de dados atÃ© a anÃ¡lise estatÃ­stica avanÃ§ada. O objetivo Ã© comparar duas versÃµes (A e B) de um produto, pÃ¡gina web ou feature para determinar qual performa melhor de acordo com mÃ©tricas prÃ©-definidas.

## ğŸ¯ Objetivos

- ğŸ“Š **Comparar a eficÃ¡cia** de duas variantes (A e B)
- ğŸ“ˆ **Determinar estatisticamente** qual versÃ£o performa melhor
- ğŸ¯ **Tomar decisÃµes baseadas em dados** para implementaÃ§Ã£o
- ğŸ” **Identificar insights** acionÃ¡veis para otimizaÃ§Ã£o

## ğŸ“‹ Estrutura do RepositÃ³rio
/teste_ab/
â”‚
â”œâ”€â”€ /data/ # ğŸ“ Dados brutos e processados
â”‚ â”œâ”€â”€ raw/ # ğŸ—ƒï¸ Dados originais
â”‚ â””â”€â”€ processed/ # âš™ï¸ Dados tratados
â”‚
â”œâ”€â”€ /notebooks/ # ğŸ““ Jupyter notebooks de anÃ¡lise
â”‚ â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚ â”œâ”€â”€ 02_ab_test_analysis.ipynb
â”‚ â””â”€â”€ 03_statistical_analysis.ipynb
â”‚
â”œâ”€â”€ /src/ # ğŸ’» CÃ³digo fonte
â”‚ â”œâ”€â”€ data_processing.py # ğŸ§¹ Scripts de limpeza
â”‚ â”œâ”€â”€ ab_test.py # ğŸ“Š AnÃ¡lise estatÃ­stica
â”‚ â””â”€â”€ visualization.py # ğŸ“ˆ GeraÃ§Ã£o de grÃ¡ficos
â”‚
â”œâ”€â”€ /results/ # ğŸ“Š Resultados e visualizaÃ§Ãµes
â”‚ â”œâ”€â”€ plots/ # ğŸ¨ GrÃ¡ficos e visualizaÃ§Ãµes
â”‚ â”œâ”€â”€ ab_test_report.pdf # ğŸ“„ RelatÃ³rio final
â”‚ â””â”€â”€ summary_results.csv # ğŸ’¾ Resultados sumarizados
â”‚
â”œâ”€â”€ requirements.txt # ğŸ“¦ DependÃªncias do projeto
â””â”€â”€ README.md # ğŸ“– Este arquivo

text

## ğŸ”§ PrÃ©-requisitos

- **Python 3.8+** ğŸ
- **Pip** (gerenciador de pacotes)
- **Bibliotecas listadas em requirements.txt**

### ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/teste-ab.git
cd teste-ab

# Instale as dependÃªncias
pip install -r requirements.txt
ğŸš€ Como Executar
1. ğŸ“¥ PreparaÃ§Ã£o dos Dados
bash
python src/data_processing.py --input data/raw/ --output data/processed/
2. ğŸ“Š Executar AnÃ¡lise do Teste A/B
bash
python src/ab_test.py --data data/processed/ab_test_data.csv --metric conversion_rate
3. ğŸ“ˆ Gerar VisualizaÃ§Ãµes
bash
python src/visualization.py --data data/processed/ab_test_data.csv --output results/plots/
âš™ï¸ OpÃ§Ãµes de ParÃ¢metros
ParÃ¢metro	DescriÃ§Ã£o	PadrÃ£o	Exemplo
--data	Caminho para os dados	data/processed/	--data dados/experimento.csv
--metric	MÃ©trica a ser analisada	conversion_rate	--metric revenue_per_user
--confidence	NÃ­vel de confianÃ§a estatÃ­stica	0.95	--confidence 0.99
--alpha	NÃ­vel de significÃ¢ncia	0.05	--alpha 0.01
--output	DiretÃ³rio de saÃ­da	results/	--output resultados/
ğŸ“Š MÃ©tricas Analisadas
MÃ©trica	DescriÃ§Ã£o	Tipo de AnÃ¡lise
âœ… Taxa de conversÃ£o	Percentual de usuÃ¡rios que convertem	ProporÃ§Ã£o
â° Tempo na pÃ¡gina	Tempo mÃ©dio de permanÃªncia	ContÃ­nua
ğŸ–±ï¸ CTR	Click-Through Rate	ProporÃ§Ã£o
ğŸ’° Receita por usuÃ¡rio	Valor mÃ©dio gerado por usuÃ¡rio	ContÃ­nua
âŒ Taxa de rejeiÃ§Ã£o	Percentual de rejeiÃ§Ãµes	ProporÃ§Ã£o
ğŸ“‰ Taxa de retenÃ§Ã£o	Percentual de retenÃ§Ã£o de usuÃ¡rios	ProporÃ§Ã£o
ğŸ”„ Taxa de engajamento	NÃ­vel de engajamento dos usuÃ¡rios	ContÃ­nua
ğŸ“ˆ MÃ©todos EstatÃ­sticos Implementados
ğŸ¯ Testes de HipÃ³teses
Teste T para amostras independentes

Teste Z para proporÃ§Ãµes

Teste de Mann-Whitney U (nÃ£o paramÃ©trico)

ğŸ“Š AnÃ¡lise EstatÃ­stica
CÃ¡lculo do valor-p e significÃ¢ncia estatÃ­stica

Intervalos de confianÃ§a de 95% e 99%

Tamanho do efeito (Cohen's d, Glass's delta)

AnÃ¡lise de poder estatÃ­stico (Power Analysis)

Teste de normalidade (Shapiro-Wilk, Kolmogorov-Smirnov)

Teste de variÃ¢ncia (Levene's test, Bartlett's test)

ğŸ“¶ MÃ©todos AvanÃ§ados
AnÃ¡lise de regressÃ£o para controle de covariÃ¡veis

Testes de mÃºltiplas comparaÃ§Ãµes (correÃ§Ã£o de Bonferroni)

AnÃ¡lise de sensibilidade

ğŸ“ Exemplo de Uso Completo
python
from src.ab_test import ABTestAnalyzer
from src.visualization import ResultVisualizer
import pandas as pd

# ğŸ“¥ Carregar dados
data = pd.read_csv('data/processed/ab_test_data.csv')

# ğŸ”§ Inicializar analisador
analyzer = ABTestAnalyzer(
    data=data,
    group_column='variante',
    metric_column='conversion_rate',
    confidence_level=0.95
)

# ğŸ“Š Executar anÃ¡lise completa
results = analyzer.run_complete_analysis()

# ğŸ“ˆ Visualizar resultados
visualizer = ResultVisualizer(results)
visualizer.plot_conversion_rates(save_path='results/plots/conversion_rates.png')
visualizer.plot_confidence_intervals(save_path='results/plots/confidence_intervals.png')

# ğŸ“‹ Gerar relatÃ³rio HTML
report = analyzer.generate_html_report('results/ab_test_report.html')

print(f"ğŸ“Š Resultados da anÃ¡lise:")
print(f"Valor-p: {results['p_value']:.4f}")
print(f"Significativo: {results['is_significant']}")
print(f"Efeito: {results['effect_size']:.3f}")
ğŸ“Œ Resultados Esperados
ğŸ“„ RelatÃ³rio EstatÃ­stico
SumÃ¡rio executivo com recomendaÃ§Ãµes

Tabelas detalhadas com todas as mÃ©tricas

AnÃ¡lise de significÃ¢ncia estatÃ­stica e prÃ¡tica

Intervalos de confianÃ§a para todas as mÃ©tricas

ğŸ“Š VisualizaÃ§Ãµes
ğŸ“ˆ GrÃ¡ficos de barras comparativos

ğŸ“Š DistribuiÃ§Ãµes das mÃ©tricas por grupo

ğŸ¯ Intervalos de confianÃ§a visualizados

ğŸ“‰ TendÃªncias temporais (se aplicÃ¡vel)

ğŸ’¾ ExportaÃ§Ãµes
CSV/Excel com resultados detalhados

PDF/HTML com relatÃ³rio completo

JSON para integraÃ§Ã£o com outras ferramentas

ğŸ“… Cronograma do Projeto
Fase	DuraÃ§Ã£o	EntregÃ¡veis
â³ PreparaÃ§Ã£o	1 semana	DefiniÃ§Ã£o de mÃ©tricas, tamanho amostral
ğŸ“¥ Coleta	2-4 semanas	Dados brutos, logging implementado
ğŸ“Š AnÃ¡lise	1 semana	AnÃ¡lise estatÃ­stica, visualizaÃ§Ãµes
ğŸ“„ RelatÃ³rio	3 dias	RelatÃ³rio final, recomendaÃ§Ãµes
ğŸ¯ ImplementaÃ§Ã£o	1-2 semanas	Deployment da versÃ£o vencedora
ğŸ› ï¸ Ferramentas Utilizadas
ğŸ Linguagens e Frameworks
Python 3.8+ - Linguagem principal

Pandas - ManipulaÃ§Ã£o de dados

NumPy - ComputaÃ§Ã£o numÃ©rica

SciPy - EstatÃ­stica cientÃ­fica

StatsModels - Modelagem estatÃ­stica

ğŸ“Š VisualizaÃ§Ã£o
Matplotlib - GrÃ¡ficos estÃ¡ticos

Seaborn - VisualizaÃ§Ã£o estatÃ­stica

Plotly - GrÃ¡ficos interativos

ğŸ““ Ambiente de Desenvolvimento
Jupyter Notebook - AnÃ¡lise exploratÃ³ria

VS Code - IDE principal

Git - Controle de versÃ£o

ğŸ¤ Guia de ContribuiÃ§Ã£o
ğŸ´ Como Contribuir
Fork o projeto

Clone seu fork:

bash
git clone https://github.com/seu-usuario/teste-ab.git
Crie uma branch para sua feature:

bash
git checkout -b feature/nova-funcionalidade
Commit suas mudanÃ§as:

bash
git commit -m 'feat: adiciona nova mÃ©trica de engajamento'
Push para a branch:

bash
git push origin feature/nova-funcionalidade
Abra um Pull Request

ğŸ“ PadrÃµes de Commit
Tipo	Emoji	DescriÃ§Ã£o
feat	âœ¨	Nova funcionalidade
fix	ğŸ›	CorreÃ§Ã£o de bug
docs	ğŸ“š	DocumentaÃ§Ã£o
style	ğŸ’„	FormataÃ§Ã£o de cÃ³digo
refactor	â™»ï¸	RefatoraÃ§Ã£o de cÃ³digo
test	âœ…	AdiÃ§Ã£o de testes
chore	ğŸ”§	Tarefas de manutenÃ§Ã£o
ğŸ“š Recursos Adicionais
ğŸ“– DocumentaÃ§Ã£o
ğŸ“Š Guia Completo de Testes A/B

ğŸ§® Calculadora de Tamanho de Amostra

ğŸ“ˆ Artigos sobre EstatÃ­stica

ğŸ“ Cursos Recomendados
ğŸ“Š EstatÃ­stica para Data Science

ğŸ¯ Testes A/B na PrÃ¡tica

ğŸ“ˆ VisualizaÃ§Ã£o de Dados

ğŸ”§ Ferramentas Ãšteis
ğŸ“ Calculadora EstatÃ­stica Online

ğŸ“Š Gerador de GrÃ¡ficos

ğŸ¯ Simulador de Testes A/B

ğŸ› Troubleshooting
Problemas Comuns
Erro de dependÃªncias:

bash
pip install --upgrade -r requirements.txt
Dados corrompidos:

bash
python src/data_processing.py --check-integrity
MemÃ³ria insuficiente:

bash
python src/ab_test.py --chunk-size 1000
ğŸ“Š OtimizaÃ§Ã£o de Performance
Para conjuntos de dados grandes:

bash
# Usar processamento em chunks
python src/ab_test.py --chunk-size 5000 --use-dask

# Habilitar cache de resultados
python src/ab_test.py --enable-cache
ğŸ“§ Suporte e Contato
Para dÃºvidas, sugestÃµes ou problemas:

JosÃ© Dinis Carlos Cabicho
ğŸ“§ Email: jcabicho@gmail.com
ğŸ’¼ LinkedIn: linkedin.com/in/jose-cabicho
ğŸ™ GitHub: github.com/jcabicho
ğŸ¦ Twitter: @cabicho

ğŸš€ Relatar Problemas
Encontrou um bug? Por favor, abra uma issue no GitHub incluindo:

ğŸ“‹ DescriÃ§Ã£o detalhada do problema

ğŸ” Passos para reproduzir

ğŸ“Š Dados de exemplo (se aplicÃ¡vel)

ğŸ–¥ï¸ ConfiguraÃ§Ã£o do ambiente

ğŸ“„ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para detalhes.

ğŸ™Œ Agradecimentos
Equipe da Escola de Dados pelo desafio

Comunidade Python pelas bibliotecas incrÃ­veis

Stack Overflow pelas soluÃ§Ãµes compartilhadas

â­ Este projeto demonstra competÃªncias avanÃ§adas em teste A/B, anÃ¡lise estatÃ­stica e tomada de decisÃ£o baseada em dados.

ğŸš€ Pronto para transformar dados em decisÃµes!


README - Teste A/B

ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o de um teste A/B completo, desde a coleta de dados atÃ© a anÃ¡lise estatÃ­stica. O objetivo Ã© comparar duas versÃµes (A e B) de um produto, pÃ¡gina web ou feature para determinar qual performa melhor de acordo com mÃ©tricas prÃ©-definidas.

ğŸ¯ Objetivos

Comparar a eficÃ¡cia de duas variantes (A e B)

Determinar estatisticamente qual versÃ£o performa melhor

Tomar decisÃµes baseadas em dados para implementaÃ§Ã£o

ğŸ“‹ Estrutura do RepositÃ³rio
```
/teste_ab/
â”‚
|
â”œâ”€â”€ /data/                    # Dados brutos e processados
â”‚   â”œâ”€â”€ raw/                  # Dados originais
â”‚   â””â”€â”€ processed/            # Dados tratados
â”‚
â”œâ”€â”€ /notebooks/               # Jupyter notebooks de anÃ¡lise
â”‚   â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚   â””â”€â”€ 02_ab_test_analysis.ipynb
â”‚
â”œâ”€â”€ /src/                     # CÃ³digo fonte
â”‚   â”œâ”€â”€ data_processing.py    # Scripts de limpeza
â”‚   â””â”€â”€ ab_test.py            # AnÃ¡lise estatÃ­stica
â”‚
â”œâ”€â”€ results/                  # Resultados e visualizaÃ§Ãµes
â”‚   â”œâ”€â”€ plots/                # GrÃ¡ficos
â”‚   â””â”€â”€ ab_test_report.pdf    # RelatÃ³rio final
â”‚
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â””â”€â”€ README.md                 # Este arquivo
```

ğŸ”§ PrÃ©-requisitos
```
Python 3.8+
```
Bibliotecas listadas em requirements.txt
```
pip install -r requirements.txt
```
ğŸš€ Como Executar

1. PreparaÃ§Ã£o dos Dados
```
python src/data_processing.py --input data/raw/ --output data/processed/
```
2. Executar AnÃ¡lise do Teste A/B
```
python src/ab_test.py --data data/processed/ab_test_data.csv --metric conversion_rate
```
3. OpÃ§Ãµes de ParÃ¢metros
```
ParÃ¢metro	  | DescriÃ§Ã£o	                    | PadrÃ£o
--data	      | Caminho para os dados	        | data/processed/
--metric	  | MÃ©trica a ser analisada	        | conversion_rate
--confidence  | NÃ­vel de confianÃ§a estatÃ­stica	| 0.95
```
ğŸ“Š MÃ©tricas Analisadas
```
Taxa de conversÃ£o

Tempo na pÃ¡gina

CTR (Click-Through Rate)

Receita por usuÃ¡rio

Taxa de rejeiÃ§Ã£o
```

ğŸ“ˆ MÃ©todos EstatÃ­sticos
```
Teste de hipÃ³teses (bicaudal)

CÃ¡lculo do valor-p

Intervalos de confianÃ§a

Tamanho do efeito (Cohen's d)

AnÃ¡lise de poder estatÃ­stico
```
ğŸ“ Exemplo de Uso
```
from src.ab_test import ABTestAnalyzer
```
# Carregar dados
```
analyzer = ABTestAnalyzer('data/processed/ab_test_results.csv')
```
# Rodar anÃ¡lise
results = analyzer.run_analysis(metric='conversion_rate')

# Visualizar resultados
analyzer.plot_results(save_path='results/plots/conversion_rate.png')

ğŸ“Œ Resultados Esperados

RelatÃ³rio estatÃ­stico completo

VisualizaÃ§Ãµes comparando os grupos

RecomendaÃ§Ã£o sobre qual versÃ£o implementar

AnÃ¡lise de significÃ¢ncia prÃ¡tica e estatÃ­stica

ğŸ“… Cronograma
```
Fase de PreparaÃ§Ã£o: 1 semana

Coleta de Dados: 2-4 semanas

AnÃ¡lise: 1 semana

RelatÃ³rio: 3 dias
```
ğŸ¤ ContribuiÃ§Ã£o
```
FaÃ§a um fork do projeto

Crie sua branch (git checkout -b feature/nova-analise)

Commit suas mudanÃ§as (git commit -m 'Adiciona nova mÃ©trica')

Push para a branch (git push origin feature/nova-analise)

Abra um Pull Request
```
ğŸ“š Recursos Adicionais
```
Guia Completo de Testes A/B

Calculadora de Tamanho de Amostra

Artigos sobre EstatÃ­stica para Testes A/B
```
ğŸ“§ Contato
```
Para dÃºvidas ou sugestÃµes, entre em contato com:
[JosÃ© Dinis Carlos Cabicho] - [jcabicho@gmail.com] - [@cabicho]
```